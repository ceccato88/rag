"""Test the multimodal RAG system with a real query."""

import asyncio
import os
import sys
from pathlib import Path

# Add src to path and setup environment
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from config import get_config

def setup_environment():
    """Setup environment using flexible config system."""
    config = get_config()
    
    if not config.is_ready():
        print("âŒ Environment configuration incomplete")
        config.print_status()
        return False
    
    print(f"âœ… Environment loaded from: {config.env_file_used or 'system environment'}")
    return True

async def test_real_query():
    """Test the system with a real query."""
    print("ğŸ§ª Testing Multimodal RAG with Real Query")
    print("=" * 50)
    
    try:
        # Import agents
        from rag_agents.agents.lead_rag import LeadRAGAgent, LeadRAGConfig
        from rag_agents.agents.retriever import MultimodalRetrieverAgent, RetrieverConfig
        from rag_agents.agents.reranker import MultimodalRerankerAgent, RerankerConfig
        from rag_agents.agents.context_analyzer import ContextAnalyzerAgent, ContextAnalyzerConfig
        from rag_agents.agents.answer_generator import MultimodalAnswerAgent, AnswerGeneratorConfig
        from rag_agents.agents.base import AgentContext
        
        print("âœ… Agents imported")
        
        # Initialize configurations
        retriever_config = RetrieverConfig(max_candidates=5)
        reranker_config = RerankerConfig(openai_api_key=os.getenv("OPENAI_API_KEY"))
        analyzer_config = ContextAnalyzerConfig(openai_api_key=os.getenv("OPENAI_API_KEY"))
        generator_config = AnswerGeneratorConfig(openai_api_key=os.getenv("OPENAI_API_KEY"))
        lead_config = LeadRAGConfig(openai_api_key=os.getenv("OPENAI_API_KEY"))
        
        print("âœ… Configurations created")
        
        # Initialize agents
        retriever = MultimodalRetrieverAgent(config=retriever_config, name="Retriever")
        reranker = MultimodalRerankerAgent(config=reranker_config, name="Reranker")
        context_analyzer = ContextAnalyzerAgent(config=analyzer_config, name="ContextAnalyzer")
        answer_generator = MultimodalAnswerAgent(config=generator_config, name="AnswerGenerator")
        
        print("âœ… Agents initialized")
        
        # Create lead agent
        lead_agent = LeadRAGAgent(
            retriever_agent=retriever,
            reranker_agent=reranker,
            context_analyzer_agent=context_analyzer,
            answer_generator_agent=answer_generator,
            config=lead_config,
            name="LeadAgent"
        )
        
        print("âœ… Lead agent created")
        
        # Test query
        test_query = "What are the main components of the Zep architecture?"
        context = AgentContext(
            query=test_query,
            objective="Understand the technical architecture of the Zep system",
            constraints=["Focus on technical details", "Include visual diagrams if available"]
        )
        
        print(f"\nğŸ” Running query: {test_query}")
        print("ğŸ•’ This may take a few moments...")
        
        # Run the RAG system
        start_time = asyncio.get_event_loop().time()
        result = await lead_agent.run(context)
        end_time = asyncio.get_event_loop().time()
        
        print(f"\nâ±ï¸  Processing completed in {end_time - start_time:.2f} seconds")
        print(f"ğŸ“Š Status: {result.status}")
        
        if result.status.value == "completed" and result.output:
            rag_result = result.output
            
            print("\nğŸ‰ RAG Query Successful!")
            print("=" * 50)
            
            print(f"ğŸ“‹ Query Type: {rag_result.query_decomposition.query_type}")
            print(f"ğŸ¯ Key Aspects: {', '.join(rag_result.query_decomposition.key_aspects)}")
            print(f"ğŸ“Š Total Processing Time: {rag_result.total_processing_time:.2f}s")
            print(f"ğŸ”§ Processing Steps: {len(rag_result.processing_steps)}")
            print(f"ğŸ’° Total Tokens: {rag_result.total_tokens_used}")
            print(f"ğŸ“š Documents Used: {len(rag_result.ranked_documents.documents)}")
            print(f"ğŸ¯ Confidence: {rag_result.answer.multimodal_confidence:.2f}")
            print(f"âš–ï¸  Evidence Strength: {rag_result.answer.evidence_strength}")
            
            print(f"\nğŸ“„ Answer:")
            print("-" * 60)
            print(rag_result.answer.main_response)
            print("-" * 60)
            
            if rag_result.answer.sources_used:
                print(f"\nğŸ“š Sources ({len(rag_result.answer.sources_used)}):")
                for i, source in enumerate(rag_result.answer.sources_used, 1):
                    print(f"   {i}. {source.document} - Page {source.page_number}")
            
            if rag_result.answer.limitations:
                print(f"\nâš ï¸  Limitations:")
                for limitation in rag_result.answer.limitations:
                    print(f"   â€¢ {limitation}")
            
            return True
        else:
            print(f"\nâŒ Query failed: {result.error}")
            if result.thinking:
                print("ğŸ§  Agent thinking:")
                for thought in result.thinking[-5:]:  # Show last 5 thoughts
                    print(f"   {thought}")
            return False
    
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Main function."""
    if not setup_environment():
        print("âŒ Environment setup failed")
        return
    
    success = asyncio.run(test_real_query())
    
    if success:
        print(f"\nâœ¨ Test completed successfully!")
        print("ğŸ’¡ The multimodal RAG system is working with your documents!")
    else:
        print(f"\nâš ï¸  Test had issues - check errors above")

if __name__ == "__main__":
    main()