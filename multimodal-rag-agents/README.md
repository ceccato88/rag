# Sistema de Agentes RAG Multimodal

Um sistema sofisticado de RAG (Retrieval-Augmented Generation) multiagente que usa [Instructor](https://github.com/jxnl/instructor) para sa√≠das estruturadas de LLM e suporta processamento multimodal de documentos com imagens e texto.

## Funcionalidades

- ü§ñ **Arquitetura Multiagente**: Agente RAG l√≠der decomp√µe consultas e coordena agentes especializados
- üîç **Busca Multimodal**: Integra embeddings multimodais Voyage AI com busca vetorial Astra DB
- üìä **Sa√≠das Estruturadas**: Usa Instructor para obter respostas tipadas e validadas de LLMs
- üñºÔ∏è **Processamento Visual**: Lida com documentos PDF com imagens e diagramas
- üîÑ **Re-ranqueamento Inteligente**: Re-ranqueamento inteligente de documentos com an√°lise de contexto
- ‚ö° **Execu√ß√£o Paralela**: M√∫ltiplos agentes trabalham simultaneamente para resultados mais r√°pidos
- üîß **Configura√ß√£o Flex√≠vel**: Auto-descoberta de arquivos de ambiente para flexibilidade de implanta√ß√£o

## In√≠cio R√°pido

### Instala√ß√£o

```bash
# Navegue para o diret√≥rio do projeto
cd multimodal-rag-agents

# Instale as depend√™ncias no ambiente virtual
python -m venv .venv
source .venv/bin/activate  # No Windows: .venv\Scripts\activate
pip install -e .
```

### Configura√ß√£o do Ambiente

O sistema busca automaticamente por arquivos `.env` em m√∫ltiplas localiza√ß√µes:
- Diret√≥rio atual
- Raiz do projeto
- Diret√≥rio pai
- Diret√≥rio home
- Caminhos de configura√ß√£o do sistema

Crie um arquivo `.env` em qualquer uma dessas localiza√ß√µes:

```bash
# Chaves de API Obrigat√≥rias
OPENAI_API_KEY=sua-chave-openai-aqui
VOYAGE_API_KEY=sua-chave-voyage-aqui

# Configura√ß√£o Obrigat√≥ria do Astra DB
ASTRA_DB_API_ENDPOINT=https://seu-id-database-regiao.apps.astra.datastax.com
ASTRA_DB_APPLICATION_TOKEN=AstraCS:seu-token-aqui

# Configura√ß√£o de Modelos
LLM_MODEL=gpt-4o                     # Modelo principal para Lead RAG Agent
RERANKER_MODEL=gpt-4o                # Modelo para re-ranking de documentos
CONTEXT_ANALYZER_MODEL=gpt-4o        # Modelo para an√°lise de contexto
ANSWER_GENERATOR_MODEL=gpt-4o        # Modelo para gera√ß√£o de respostas
EMBEDDING_MODEL=voyage-multimodal-3  # Modelo para embeddings multimodais

# Configura√ß√£o Opcional
COLLECTION_NAME=pdf_documents
IMAGE_DIR=pdf_images
MAX_CANDIDATES=5
```

### Executar Exemplos

```bash
# Demo r√°pido para testar o sistema
python run_demo.py

# Teste com uma consulta real
python test_real_query.py

# Exemplo abrangente com pipeline completo
python examples/basic_multimodal_rag.py
```

## Arquitetura

O sistema implementa uma arquitetura RAG multiagente hier√°rquica:

```
Consulta do Usu√°rio ‚Üí Agente RAG L√≠der ‚Üí Decomposi√ß√£o da Consulta (via Instructor)
                        ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                                                 ‚îÇ
    ‚ñº                    ‚ñº                    ‚ñº       ‚ñº
Agente      ‚Üí Agente      ‚Üí Analisador ‚Üí Gerador
Recuperador   Re-ranque     de Contexto   de Resposta
    ‚îÇ            ‚îÇ              ‚îÇ            ‚îÇ
    ‚ñº            ‚ñº              ‚ñº            ‚ñº
Embeddings   OpenAI GPT    An√°lise de    Resposta
Multimodais     Re-ranque   Qualidade     Multimodal
Voyage AI      Inteligente               
    ‚îÇ
    ‚ñº
Astra DB ‚Üí Candidatos de Documentos ‚Üí Resultado RAG Final
Banco de
Dados Vetorial
```

### Componentes Principais

1. **LeadRAGAgent**: Orquestra o pipeline RAG completo usando Instructor para an√°lise estruturada de consultas
2. **MultimodalRetrieverAgent**: Recupera documentos relevantes usando embeddings multimodais Voyage AI
3. **MultimodalRerankerAgent**: Re-ranqueia documentos inteligentemente baseado na relev√¢ncia da consulta
4. **ContextAnalyzerAgent**: Analisa qualidade e completude do contexto
5. **MultimodalAnswerAgent**: Gera respostas abrangentes com suporte a elementos visuais
6. **Configura√ß√£o Flex√≠vel**: Sistema de auto-descoberta para vari√°veis de ambiente

## Uso

### Uso B√°sico

```python
import asyncio
from src.rag_agents.agents.lead_rag import LeadRAGAgent, LeadRAGConfig
from src.rag_agents.agents.retriever import MultimodalRetrieverAgent, RetrieverConfig
from src.rag_agents.agents.reranker import MultimodalRerankerAgent, RerankerConfig
from src.rag_agents.agents.context_analyzer import ContextAnalyzerAgent, ContextAnalyzerConfig
from src.rag_agents.agents.answer_generator import MultimodalAnswerAgent, AnswerGeneratorConfig
from src.rag_agents.agents.base import AgentContext
from config import get_config

async def consulta_rag_multimodal():
    # Carregamento flex√≠vel de configura√ß√£o
    config = get_config()
    if not config.is_ready():
        print("‚ùå Configura√ß√£o de ambiente incompleta")
        config.print_status()
        return
    
    # Inicializar configura√ß√µes dos agentes
    retriever_config = RetrieverConfig(max_candidates=5)
    reranker_config = RerankerConfig(openai_api_key=config.get("OPENAI_API_KEY"))
    analyzer_config = ContextAnalyzerConfig(openai_api_key=config.get("OPENAI_API_KEY"))
    generator_config = AnswerGeneratorConfig(openai_api_key=config.get("OPENAI_API_KEY"))
    lead_config = LeadRAGConfig(openai_api_key=config.get("OPENAI_API_KEY"))
    
    # Inicializar agentes
    retriever = MultimodalRetrieverAgent(config=retriever_config, name="Recuperador")
    reranker = MultimodalRerankerAgent(config=reranker_config, name="Reranqueador")
    context_analyzer = ContextAnalyzerAgent(config=analyzer_config, name="AnalisadorContexto")
    answer_generator = MultimodalAnswerAgent(config=generator_config, name="GeradorResposta")
    
    # Criar agente l√≠der
    lead_agent = LeadRAGAgent(
        retriever_agent=retriever,
        reranker_agent=reranker,
        context_analyzer_agent=context_analyzer,
        answer_generator_agent=answer_generator,
        config=lead_config,
        name="AgenteLider"
    )
    
    # Criar contexto da consulta
    context = AgentContext(
        query="Quais s√£o os principais componentes da arquitetura do sistema?",
        objective="Entender a arquitetura t√©cnica incluindo elementos visuais",
        constraints=["Focar em detalhes t√©cnicos", "Incluir diagramas visuais se dispon√≠veis"]
    )
    
    # Executar RAG multimodal
    result = await lead_agent.run(context)
    
    if result.status.value == "completed":
        rag_result = result.output
        print(f"Resposta: {rag_result.answer.main_response}")
        print(f"Fontes: {len(rag_result.answer.sources_used)}")
        print(f"Confian√ßa: {rag_result.answer.multimodal_confidence:.2f}")
    else:
        print(f"Erro: {result.error}")

# Executar
asyncio.run(consulta_rag_multimodal())
```

### Configura√ß√£o Avan√ßada

```python
# Configura√ß√£o de recupera√ß√£o personalizada
retriever_config = RetrieverConfig(
    max_candidates=10,
    similarity_threshold=0.7,
    collection_name="documentos_personalizados"
)

# Configura√ß√£o de re-ranqueamento personalizada
reranker_config = RerankerConfig(
    openai_api_key=config.get("OPENAI_API_KEY"),
    model="gpt-4o",
    max_tokens=1024,
    temperature=0.1
)

# Configura√ß√£o de gera√ß√£o de resposta personalizada
generator_config = AnswerGeneratorConfig(
    openai_api_key=config.get("OPENAI_API_KEY"),
    model="gpt-4o",
    max_tokens=2048,
    include_visual_analysis=True
)
```

## Como Funciona

1. **Decomposi√ß√£o da Consulta**: O agente RAG l√≠der usa Instructor para analisar a consulta e determinar estrat√©gias de busca √≥timas
2. **Recupera√ß√£o Multimodal**: O agente recuperador busca documentos usando embeddings multimodais Voyage AI
3. **Re-ranqueamento Inteligente**: Documentos s√£o re-ranqueados baseados na relev√¢ncia para a consulta espec√≠fica
4. **An√°lise de Contexto**: O analisador de contexto avalia a qualidade e completude das informa√ß√µes recuperadas
5. **Gera√ß√£o de Resposta**: O gerador de resposta cria respostas abrangentes com suporte a elementos visuais

## Configura√ß√£o de Ambiente

O sistema usa um sistema de configura√ß√£o flex√≠vel que busca automaticamente por arquivos `.env` em m√∫ltiplas localiza√ß√µes:

```python
# Verificar status da configura√ß√£o
python config.py

# O sistema busca estas localiza√ß√µes automaticamente:
# 1. Diret√≥rio atual: ./env
# 2. Raiz do projeto: /caminho/para/multimodal-rag-agents/.env
# 3. Diret√≥rio pai: /caminho/para/pai/.env
# 4. Diret√≥rio home: ~/.env
# 5. Config do sistema: ~/.config/multimodal-rag/.env
# 6. Todo o sistema: /etc/multimodal-rag/.env
# 7. Caminho personalizado via vari√°vel de ambiente RAG_CONFIG_PATH
```

## Estrutura do Projeto

```
multimodal-rag-agents/
‚îú‚îÄ‚îÄ README.md                           # Este arquivo
‚îú‚îÄ‚îÄ config.py                          # Sistema de configura√ß√£o flex√≠vel
‚îú‚îÄ‚îÄ pyproject.toml                     # Depend√™ncias e config do projeto
‚îú‚îÄ‚îÄ run_demo.py                        # Demo r√°pido
‚îú‚îÄ‚îÄ test_real_query.py                 # Teste de consulta real
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îî‚îÄ‚îÄ basic_multimodal_rag.py       # Exemplo abrangente
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ rag_agents/
        ‚îú‚îÄ‚îÄ agents/                    # Todas as implementa√ß√µes de agentes
        ‚îÇ   ‚îú‚îÄ‚îÄ base.py               # Classe base de agente
        ‚îÇ   ‚îú‚îÄ‚îÄ lead_rag.py           # Orquestrador RAG l√≠der
        ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py          # Recupera√ß√£o multimodal
        ‚îÇ   ‚îú‚îÄ‚îÄ reranker.py           # Re-ranqueamento inteligente
        ‚îÇ   ‚îú‚îÄ‚îÄ context_analyzer.py   # An√°lise de qualidade de contexto
        ‚îÇ   ‚îî‚îÄ‚îÄ answer_generator.py   # Gera√ß√£o de resposta
        ‚îî‚îÄ‚îÄ models/
            ‚îî‚îÄ‚îÄ rag_models.py          # Modelos Pydantic para dados estruturados
```

## Funcionalidades Principais

### Processamento de Documentos Multimodal
- Lida com documentos PDF com imagens e diagramas incorporados
- Extrai e processa elementos visuais junto com texto
- Mant√©m contexto entre componentes de texto e visuais

### Coordena√ß√£o Inteligente de Agentes
- Agente l√≠der decomp√µe consultas em estrat√©gias de busca √≥timas
- Agentes especializados lidam com diferentes aspectos do pipeline RAG
- Processamento paralelo para melhor desempenho

### Gera√ß√£o de Sa√≠da Estruturada
- Todas as intera√ß√µes LLM usam modelos Pydantic via Instructor
- Respostas type-safe e validadas em cada etapa
- Estruturas de resultado abrangentes com metadados

### Configura√ß√£o Pronta para Produ√ß√£o
- Gerenciamento flex√≠vel de vari√°veis de ambiente
- Auto-descoberta de arquivos de configura√ß√£o
- Funciona em v√°rios cen√°rios de implanta√ß√£o

## Refer√™ncia da API

### Modelos Principais

```python
# Decomposi√ß√£o da consulta
class RAGDecomposition(BaseModel):
    query_type: str
    key_aspects: List[str]
    search_strategies: List[SearchStrategy]
    ranking_criteria: List[RankingCriterion]
    response_format: str

# Resposta estruturada
class StructuredAnswer(BaseModel):
    main_response: str
    sources_used: List[SourceReference]
    multimodal_confidence: float
    evidence_strength: str
    visual_elements_used: List[str]
    limitations: List[str]
    follow_up_suggestions: List[str]
```

### Configura√ß√µes dos Agentes

```python
# Configura√ß√£o do recuperador
class RetrieverConfig(BaseModel):
    max_candidates: int = 5
    similarity_threshold: float = 0.7
    collection_name: str = "pdf_documents"

# Configura√ß√£o do re-ranqueador  
class RerankerConfig(BaseModel):
    openai_api_key: str
    model: str = "gpt-4o"
    max_tokens: int = 512
    temperature: float = 0.1

# Configura√ß√£o do gerador de resposta
class AnswerGeneratorConfig(BaseModel):
    openai_api_key: str
    model: str = "gpt-4o"
    max_tokens: int = 2048
    include_visual_analysis: bool = True
```

## Testes

```bash
# Testar componentes do sistema
python test_real_query.py

# Executar demo r√°pido
python run_demo.py

# Testar com configura√ß√£o de ambiente
python config.py
```

## Considera√ß√µes de Desempenho

- **Processamento Paralelo**: Agentes trabalham simultaneamente para reduzir lat√™ncia
- **Efici√™ncia de Token**: Sa√≠das estruturadas minimizam uso de tokens
- **Cache**: Embeddings multimodais s√£o cacheados para consultas repetidas
- **Processamento em Lote**: M√∫ltiplos documentos processados em paralelo

## Otimiza√ß√£o de Custos

O sistema permite configurar diferentes modelos para cada agente, permitindo otimiza√ß√£o de custos:

### Configura√ß√µes Recomendadas:

**üèÜ Alta Qualidade (Recomendado)**
```bash
LLM_MODEL=gpt-4o
RERANKER_MODEL=gpt-4o
CONTEXT_ANALYZER_MODEL=gpt-4o
ANSWER_GENERATOR_MODEL=gpt-4o
```

**‚öñÔ∏è Balanceado (Custo/Qualidade)**
```bash
LLM_MODEL=gpt-4o
RERANKER_MODEL=gpt-4o
CONTEXT_ANALYZER_MODEL=gpt-4o-mini
ANSWER_GENERATOR_MODEL=gpt-4o
```

**üí∞ Otimizado para Custo**
```bash
LLM_MODEL=gpt-4o-mini
RERANKER_MODEL=gpt-4o
CONTEXT_ANALYZER_MODEL=gpt-4o-mini
ANSWER_GENERATOR_MODEL=gpt-4o-mini
```

### Recomenda√ß√µes por Agente:

- **Lead RAG Agent**: `gpt-4o` ou `gpt-4o-mini` para decomposi√ß√£o de queries
- **Reranker Agent**: `gpt-4o` obrigat√≥rio para an√°lise multimodal de qualidade
- **Context Analyzer**: `gpt-4o-mini` adequado para an√°lise de qualidade
- **Answer Generator**: `gpt-4o` recomendado para respostas de alta qualidade

## Op√ß√µes de Implanta√ß√£o

### Desenvolvimento
```bash
# Desenvolvimento local com arquivo .env
python run_demo.py
```

### Produ√ß√£o
```bash
# Vari√°veis de ambiente definidas no n√≠vel do sistema
export OPENAI_API_KEY="sua-chave"
export VOYAGE_API_KEY="sua-chave"
export ASTRA_DB_API_ENDPOINT="seu-endpoint"
export ASTRA_DB_APPLICATION_TOKEN="seu-token"

python examples/basic_multimodal_rag.py
```

### Implanta√ß√£o em Container
```bash
# Definir RAG_CONFIG_PATH para apontar para diret√≥rio de config
export RAG_CONFIG_PATH="/app/config"
# Colocar arquivo .env em /app/config/.env
```

## Contribuindo

1. Fa√ßa fork do reposit√≥rio
2. Crie uma branch de funcionalidade
3. Fa√ßa suas altera√ß√µes
4. Adicione testes para nova funcionalidade
5. Envie um pull request

## Licen√ßa

Licen√ßa MIT - veja [LICENSE](LICENSE) para detalhes.

## Agradecimentos

- Constru√≠do com [Instructor](https://github.com/jxnl/instructor) para sa√≠das estruturadas confi√°veis
- Powered by [Voyage AI](https://www.voyageai.com/) para embeddings multimodais
- Usa [Astra DB](https://www.datastax.com/products/datastax-astra) para armazenamento vetorial
- Inspirado na arquitetura de pesquisa multiagente da Anthropic

## Projetos Relacionados

- Sistema RAG original: `../search.py`, `../indexer.py`, `../evaluator.py`
- Pesquisador multiagente: `../multi-agent-researcher/`