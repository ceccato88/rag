# üîç ReAct Reasoning Pattern

## üéØ Conceito Fundamental

O sistema implementa o padr√£o **ReAct (Reasoning + Acting)** como substituto ao sistema "thinking" tradicional, fornecendo racioc√≠nio estruturado e valida√ß√£o cont√≠nua durante todo o processo de pesquisa.

## üß† Filosofia do ReAct

### Tradicional "Thinking" vs ReAct Reasoning

| Aspecto | Thinking Tradicional | ReAct Reasoning |
|---------|---------------------|-----------------|
| **Estrutura** | Texto livre, narrativo | Categorizado e estruturado |
| **Valida√ß√£o** | Manual/externa | Autom√°tica e cont√≠nua |
| **Observa√ß√µes** | Impl√≠citas | Expl√≠citas com next actions |
| **Integra√ß√£o** | Separado do sistema | Integrado no fluxo de execu√ß√£o |
| **Feedback** | Est√°tico | Din√¢mico com ajustes |
| **Rastreabilidade** | Limitada | Trace completo e estruturado |

## üîÑ As 5 Fases do ReAct

### 1. üîç Fact Gathering
**Objetivo**: Estabelecer base s√≥lida de conhecimento para fundamentar decis√µes

```python
class FactGathering(BaseModel):
    given_facts: List[str]      # Fatos explicitamente fornecidos
    recalled_facts: List[str]   # Conhecimento do sistema/dom√≠nio
    assumptions: List[str]      # Suposi√ß√µes bem fundamentadas

def gather_facts(self, task: str, context: str) -> FactGathering:
    """Coleta sistem√°tica de fatos"""
    
    # An√°lise da query para extrair fatos dados
    given_facts = self._extract_given_facts(task, context)
    
    # Recall de conhecimento relevante do dom√≠nio
    recalled_facts = self._recall_domain_knowledge(task)
    
    # Formula√ß√£o de assumptions baseadas em an√°lise
    assumptions = self._formulate_assumptions(task, context)
    
    return FactGathering(
        given_facts=given_facts,
        recalled_facts=recalled_facts, 
        assumptions=assumptions
    )
```

**Exemplo Pr√°tico**:
```python
# Para query: "Como Zep implementa temporal knowledge graphs?"
facts = FactGathering(
    given_facts=[
        "Query focuses on Zep implementation",
        "Specific interest in temporal knowledge graphs",
        "Technical implementation details requested"
    ],
    recalled_facts=[
        "Zep is a memory system for AI agents",
        "Knowledge graphs structure relational data",
        "Temporal aspects involve time-based relationships"
    ],
    assumptions=[
        "User has basic understanding of knowledge graphs",
        "Implementation details from documentation will be most valuable",
        "Comparison with other systems may provide context"
    ]
)
```

### 2. üìã Planning
**Objetivo**: Criar estrat√©gia estruturada baseada nos fatos coletados

```python
class TaskPlan(BaseModel):
    objective: str
    steps: List[str]
    expected_outcome: str
    resources_needed: List[str]

def create_plan(self, objective: str, available_resources: List[str]) -> TaskPlan:
    """Planejamento estrat√©gico estruturado"""
    
    plan = TaskPlan(
        objective=objective,
        steps=self._break_down_into_steps(objective),
        expected_outcome=self._define_success_criteria(objective),
        resources_needed=available_resources
    )
    
    # Log reasoning step
    self.add_reasoning_step(
        "planning",
        f"Created plan for: {objective}",
        f"Steps: {len(plan.steps)}, Resources: {len(plan.resources_needed)}",
        "Execute first step of the plan"
    )
    
    return plan
```

**Exemplo de Plan Gerado**:
```python
plan = TaskPlan(
    objective="Create comprehensive research plan for Zep temporal KG implementation",
    steps=[
        "Decompose query into specialized research areas",
        "Assign focus areas based on query analysis", 
        "Execute parallel subagent searches",
        "Synthesize findings with critical analysis"
    ],
    expected_outcome="Structured technical report with implementation details",
    resources_needed=["OpenAI gpt-4.1-mini", "RAG subagents", "Document search capabilities"]
)
```

### 3. ‚ö° Execution
**Objetivo**: Executar a√ß√µes planejadas com monitoramento cont√≠nuo

```python
def execute_step(self, step_description: str, action_taken: str, result: str) -> ReasoningStep:
    """Execu√ß√£o monitorada com logging estruturado"""
    
    step = self.add_reasoning_step(
        "execution",
        f"Executing: {step_description}",
        f"Action: {action_taken}\nResult: {result}",
        "Evaluate result and determine next step"
    )
    
    self.iteration_count += 1
    return step
```

**Exemplo de Execution Trace**:
```python
# Step 1
execute_step(
    "Decompose query into specialized tasks",
    "LLM analysis with focus area selection",
    "Generated 3 tasks: conceptual, technical, comparative"
)

# Step 2  
execute_step(
    "Execute parallel subagent searches", 
    "Launched 3 RAG subagents simultaneously",
    "All 3 subagents completed successfully in 4.2s"
)

# Step 3
execute_step(
    "Synthesize results with advanced AI",
    "GPT-4.1 critical analysis of all findings",
    "Generated comprehensive synthesis with cross-references"
)
```

### 4. ‚úÖ Validation
**Objetivo**: Verificar progresso e detectar problemas automaticamente

```python
class ValidationResult(BaseModel):
    is_task_completed: bool
    is_in_loop: bool
    progress_summary: str
    next_instruction: Optional[str]
    confidence_level: float

def validate_progress(self, original_task: str) -> ValidationResult:
    """Valida√ß√£o autom√°tica do progresso"""
    
    # An√°lise de completude
    is_completed = self._assess_task_completion(original_task)
    
    # Detec√ß√£o de loops de racioc√≠nio
    is_in_loop = self._detect_reasoning_loop()
    
    # C√°lculo de confian√ßa baseado em m√©tricas
    confidence = self._calculate_confidence()
    
    # Determina√ß√£o da pr√≥xima a√ß√£o
    next_instruction = None if is_completed else self._determine_next_action()
    
    validation = ValidationResult(
        is_task_completed=is_completed,
        is_in_loop=is_in_loop,
        progress_summary=self._summarize_progress(),
        next_instruction=next_instruction,
        confidence_level=confidence
    )
    
    return validation
```

**Algoritmos de Detec√ß√£o**:
```python
def _detect_reasoning_loop(self) -> bool:
    """Detecta padr√µes repetitivos no reasoning"""
    
    if len(self.reasoning_history) < 4:
        return False
    
    # Analisa √∫ltimos 4 steps
    recent_steps = self.reasoning_history[-4:]
    step_types = [s.step_type for s in recent_steps]
    
    # Loop detectado se muita repeti√ß√£o
    return len(set(step_types)) <= 2 and self.iteration_count > 3

def _calculate_confidence(self) -> float:
    """Calcula n√≠vel de confian√ßa baseado em progresso"""
    
    execution_steps = len([s for s in self.reasoning_history if s.step_type == "execution"])
    validation_steps = len([s for s in self.reasoning_history if s.step_type == "validation"])
    reflection_steps = len([s for s in self.reasoning_history if s.step_type == "reflection"])
    
    # Fatores positivos
    base_confidence = min(1.0, (execution_steps * 0.3 + validation_steps * 0.2))
    
    # Penalidades
    loop_penalty = 0.3 if self._detect_reasoning_loop() else 0.0
    reflection_penalty = reflection_steps * 0.1
    
    return max(0.0, base_confidence - loop_penalty - reflection_penalty)
```

### 5. üîÑ Reflection & Adjustment
**Objetivo**: Aprender com erros e ajustar estrat√©gia dinamicamente

```python
def reflect_and_adjust(self, what_went_wrong: str) -> TaskPlan:
    """Reflex√£o cr√≠tica e ajuste de estrat√©gia"""
    
    self.add_reasoning_step(
        "reflection",
        f"Reflecting on issues: {what_went_wrong}",
        "Analyzing failures and adjusting approach",
        "Recreate improved plan"
    )
    
    # Atualiza assumptions baseado no que aprendeu
    if "timeout" in what_went_wrong.lower():
        self._adjust_timeout_assumptions()
    elif "no results" in what_went_wrong.lower():
        self._adjust_search_strategy()
    
    # Gera novo plano melhorado
    improved_plan = self._create_improved_plan(what_went_wrong)
    
    return improved_plan
```

## üîó Integra√ß√£o com Sistema Multi-Agente

### ReAct no Lead Researcher
```python
class OpenAILeadResearcher:
    def __init__(self):
        self.reasoner = ReActReasoner(f"OpenAI Lead Researcher ({self.agent_id})")
    
    async def plan(self, context: AgentContext):
        """Planning com ReAct reasoning"""
        
        # 1. Fact gathering
        facts = self.reasoner.gather_facts(
            task=f"Research planning for: {context.query}",
            context=f"Objective: {context.objective}"
        )
        
        # 2. Enhanced reasoning com an√°lise cr√≠tica
        facts.assumptions = self._create_sophisticated_assumptions(context.query)
        
        # 3. Planning
        plan = self.reasoner.create_plan(
            objective=f"Create comprehensive research plan for: {context.query}",
            available_resources=["OpenAI gpt-4.1-mini", "RAG subagents"]
        )
        
        # 4. Execute planning (LLM ou heuristic)
        return await self._execute_planning_with_reasoning(context, facts, plan)
```

### Continuidade na S√≠ntese
```python
def _advanced_ai_synthesis(self, tasks, successful_results):
    """S√≠ntese que continua o reasoning inicial"""
    
    # Integra trace completo do reasoning
    reasoning_trace = self.reasoner.get_reasoning_trace()
    
    synthesis_prompt = f"""
    CONTEXTO DO PROCESSO DE REASONING:
    {reasoning_trace}
    
    INSTRU√á√ïES PARA S√çNTESE CR√çTICA AVAN√áADA:
    1. **Continuidade do Reasoning**: Continue o processo iniciado no planejamento
    2. **Valida√ß√£o Cr√≠tica**: Avalie consist√™ncia baseado no reasoning trace  
    3. **Reflex√£o sobre o Processo**: Avalie se resultados confirmam assumptions iniciais
    4. **Gaps e Limita√ß√µes**: Identifique lacunas baseado no planejado vs encontrado
    
    Produza s√≠ntese que demonstre continuidade e evolu√ß√£o do reasoning inicial.
    """
    
    # Final validation
    validation = self.reasoner.validate_progress(f"Synthesis for: {tasks[0]['query']}")
    
    return synthesized_result
```

## üìä Trace Visualization

### Reasoning Trace Format
```python
def get_reasoning_trace(self) -> str:
    """Gera trace leg√≠vel do processo completo"""
    
    trace = f"=== Trace de Racioc√≠nio - {self.agent_name} ===\n\n"
    
    for i, step in enumerate(self.reasoning_history, 1):
        trace += f"üîç Passo {i}: {step.step_type.upper()}\n"
        trace += f"‚è∞ {step.timestamp.strftime('%H:%M:%S')}\n"
        trace += f"üí≠ {step.content}\n"
        
        if step.observations:
            trace += f"üëÅÔ∏è Observa√ß√µes: {step.observations}\n"
        
        if step.next_action:
            trace += f"‚û°Ô∏è Pr√≥xima a√ß√£o: {step.next_action}\n"
        
        trace += "\n" + "‚îÄ" * 50 + "\n\n"
    
    return trace
```

**Exemplo de Trace**:
```
=== Trace de Racioc√≠nio - OpenAI Lead Researcher (abc-123) ===

üîç Passo 1: FACT_GATHERING
‚è∞ 14:32:15
üí≠ Coletando fatos para: Research planning for Zep temporal knowledge graphs
üëÅÔ∏è Observa√ß√µes: Query complexity: high, Technical depth: high
‚û°Ô∏è Pr√≥xima a√ß√£o: Analisar fatos dados e relembrar conhecimento relevante

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üîç Passo 2: PLANNING  
‚è∞ 14:32:16
üí≠ Criando plano para: Create comprehensive research plan for Zep temporal KG
üëÅÔ∏è Observa√ß√µes: Recursos dispon√≠veis: ['OpenAI gpt-4.1-mini', 'RAG subagents']
‚û°Ô∏è Pr√≥xima a√ß√£o: Desenvolver plano estruturado em etapas

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

üîç Passo 3: EXECUTION
‚è∞ 14:32:17  
üí≠ Executando: LLM-based decomposition informed by ReAct reasoning
üëÅÔ∏è Observa√ß√µes: Integrating manual reasoning with gpt-4.1-mini for optimal focus area selection
‚û°Ô∏è Pr√≥xima a√ß√£o: Avaliar resultado e determinar pr√≥ximo passo
```

## üéØ Benefits do ReAct Pattern

### 1. **Structured Thinking**
- **Antes**: Pensamento livre e n√£o estruturado
- **Depois**: Categorias claras (fact gathering, planning, execution, validation, reflection)

### 2. **Continuous Validation**
- **Antes**: Valida√ß√£o manual ao final
- **Depois**: Valida√ß√£o autom√°tica a cada step com m√©tricas de confian√ßa

### 3. **Loop Detection**
- **Antes**: Loops passavam despercebidos
- **Depois**: Detec√ß√£o autom√°tica e ajuste de estrat√©gia

### 4. **Traceability**
- **Antes**: Dif√≠cil rastrear como decis√µes foram tomadas
- **Depois**: Trace completo de todo o processo de reasoning

### 5. **Dynamic Adjustment**
- **Antes**: Estrat√©gia fixa durante execu√ß√£o
- **Depois**: Ajustes din√¢micos baseados em feedback

## üîß Configuration & Tuning

### Reasoning Parameters
```python
class ReActConfig:
    max_iterations: int = 10
    confidence_threshold: float = 0.7
    loop_detection_window: int = 4
    reflection_trigger_threshold: int = 3
    
    # Timeouts
    step_timeout: float = 30.0
    total_reasoning_timeout: float = 300.0
    
    # Quality metrics
    min_execution_steps: int = 1
    min_confidence_for_completion: float = 0.5
```

### Customization Points
```python
class CustomReActReasoner(ReActReasoner):
    def _assess_task_completion(self, original_task: str) -> bool:
        """Custom completion assessment"""
        # Domain-specific completion logic
        return super()._assess_task_completion(original_task)
    
    def _determine_next_action(self) -> Optional[str]:
        """Custom action determination"""
        # Domain-specific next action logic
        return super()._determine_next_action()
```

---

## üìö Links Relacionados

- [ü§ñ Sistema Multi-Agente](multi-agent.md) - Como ReAct se integra com agentes
- [üèõÔ∏è Arquitetura](architecture.md) - Vis√£o geral do sistema
- [üìä Pipeline RAG](rag-pipeline.md) - RAG com reasoning  
- [‚ö° Performance](performance.md) - Impacto do reasoning na performance
- [üîß Troubleshooting](troubleshooting.md) - Debug de reasoning issues