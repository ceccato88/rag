# ğŸ” ReAct Reasoning Pattern

## ğŸ¯ Conceito Fundamental

O sistema implementa o padrÃ£o **ReAct (Reasoning + Acting)** como substituto ao sistema "thinking" tradicional, fornecendo raciocÃ­nio estruturado e validaÃ§Ã£o contÃ­nua durante todo o processo de pesquisa.

## ğŸ§  Filosofia do ReAct

### Tradicional "Thinking" vs ReAct Reasoning

| Aspecto | Thinking Tradicional | ReAct Reasoning |
|---------|---------------------|-----------------|
| **Estrutura** | Texto livre, narrativo | Categorizado e estruturado |
| **ValidaÃ§Ã£o** | Manual/externa | AutomÃ¡tica e contÃ­nua |
| **ObservaÃ§Ãµes** | ImplÃ­citas | ExplÃ­citas com next actions |
| **IntegraÃ§Ã£o** | Separado do sistema | Integrado no fluxo de execuÃ§Ã£o |
| **Feedback** | EstÃ¡tico | DinÃ¢mico com ajustes |
| **Rastreabilidade** | Limitada | Trace completo e estruturado |

## ğŸ”„ As 5 Fases do ReAct

### 1. ğŸ” Fact Gathering
**Objetivo**: Estabelecer base sÃ³lida de conhecimento para fundamentar decisÃµes

```python
class FactGathering(BaseModel):
    given_facts: List[str]      # Fatos explicitamente fornecidos
    recalled_facts: List[str]   # Conhecimento do sistema/domÃ­nio
    assumptions: List[str]      # SuposiÃ§Ãµes bem fundamentadas

def gather_facts(self, task: str, context: str) -> FactGathering:
    """Coleta sistemÃ¡tica de fatos"""
    
    # AnÃ¡lise da query para extrair fatos dados
    given_facts = self._extract_given_facts(task, context)
    
    # Recall de conhecimento relevante do domÃ­nio
    recalled_facts = self._recall_domain_knowledge(task)
    
    # FormulaÃ§Ã£o de assumptions baseadas em anÃ¡lise
    assumptions = self._formulate_assumptions(task, context)
    
    return FactGathering(
        given_facts=given_facts,
        recalled_facts=recalled_facts, 
        assumptions=assumptions
    )
```

**Exemplo PrÃ¡tico**:
```python
# Para query: "Como Zep implementa temporal knowledge graphs?"
facts = FactGathering(
    given_facts=[
        "Query focuses on Zep implementation",
        "Specific interest in temporal knowledge graphs",
        "Technical implementation details requested"
    ],
    recalled_facts=[
        "Zep is a memory system for AI agents",
        "Knowledge graphs structure relational data",
        "Temporal aspects involve time-based relationships"
    ],
    assumptions=[
        "User has basic understanding of knowledge graphs",
        "Implementation details from documentation will be most valuable",
        "Comparison with other systems may provide context"
    ]
)
```

### 2. ğŸ“‹ Planning
**Objetivo**: Criar estratÃ©gia estruturada baseada nos fatos coletados

```python
class TaskPlan(BaseModel):
    objective: str
    steps: List[str]
    expected_outcome: str
    resources_needed: List[str]

def create_plan(self, objective: str, available_resources: List[str]) -> TaskPlan:
    """Planejamento estratÃ©gico estruturado"""
    
    plan = TaskPlan(
        objective=objective,
        steps=self._break_down_into_steps(objective),
        expected_outcome=self._define_success_criteria(objective),
        resources_needed=available_resources
    )
    
    # Log reasoning step
    self.add_reasoning_step(
        "planning",
        f"Created plan for: {objective}",
        f"Steps: {len(plan.steps)}, Resources: {len(plan.resources_needed)}",
        "Execute first step of the plan"
    )
    
    return plan
```

**Exemplo de Plan Gerado**:
```python
plan = TaskPlan(
    objective="Create comprehensive research plan for Zep temporal KG implementation",
    steps=[
        "Decompose query into specialized research areas",
        "Assign focus areas based on query analysis", 
        "Execute parallel subagent searches",
        "Synthesize findings with critical analysis"
    ],
    expected_outcome="Structured technical report with implementation details",
    resources_needed=["OpenAI gpt-4.1-mini", "RAG subagents", "Document search capabilities"]
)
```

### 3. âš¡ Execution
**Objetivo**: Executar aÃ§Ãµes planejadas com monitoramento contÃ­nuo

```python
def execute_step(self, step_description: str, action_taken: str, result: str) -> ReasoningStep:
    """ExecuÃ§Ã£o monitorada com logging estruturado"""
    
    step = self.add_reasoning_step(
        "execution",
        f"Executing: {step_description}",
        f"Action: {action_taken}\nResult: {result}",
        "Evaluate result and determine next step"
    )
    
    self.iteration_count += 1
    return step
```

**Exemplo de Execution Trace**:
```python
# Step 1
execute_step(
    "Decompose query into specialized tasks",
    "LLM analysis with focus area selection",
    "Generated 3 tasks: conceptual, technical, comparative"
)

# Step 2  
execute_step(
    "Execute parallel subagent searches", 
    "Launched 3 RAG subagents simultaneously",
    "All 3 subagents completed successfully in 4.2s"
)

# Step 3
execute_step(
    "Synthesize results with advanced AI",
    "GPT-4.1 critical analysis of all findings",
    "Generated comprehensive synthesis with cross-references"
)
```

### 4. âœ… Validation
**Objetivo**: Verificar progresso e detectar problemas automaticamente

```python
class ValidationResult(BaseModel):
    is_task_completed: bool
    is_in_loop: bool
    progress_summary: str
    next_instruction: Optional[str]
    confidence_level: float

def validate_progress(self, original_task: str) -> ValidationResult:
    """ValidaÃ§Ã£o automÃ¡tica do progresso"""
    
    # AnÃ¡lise de completude
    is_completed = self._assess_task_completion(original_task)
    
    # DetecÃ§Ã£o de loops de raciocÃ­nio
    is_in_loop = self._detect_reasoning_loop()
    
    # CÃ¡lculo de confianÃ§a baseado em mÃ©tricas
    confidence = self._calculate_confidence()
    
    # DeterminaÃ§Ã£o da prÃ³xima aÃ§Ã£o
    next_instruction = None if is_completed else self._determine_next_action()
    
    validation = ValidationResult(
        is_task_completed=is_completed,
        is_in_loop=is_in_loop,
        progress_summary=self._summarize_progress(),
        next_instruction=next_instruction,
        confidence_level=confidence
    )
    
    return validation
```

**Algoritmos de DetecÃ§Ã£o**:
```python
def _detect_reasoning_loop(self) -> bool:
    """Detecta padrÃµes repetitivos no reasoning"""
    
    if len(self.reasoning_history) < 4:
        return False
    
    # Analisa Ãºltimos 4 steps
    recent_steps = self.reasoning_history[-4:]
    step_types = [s.step_type for s in recent_steps]
    
    # Loop detectado se muita repetiÃ§Ã£o
    return len(set(step_types)) <= 2 and self.iteration_count > 3

def _calculate_confidence(self) -> float:
    """Calcula nÃ­vel de confianÃ§a baseado em progresso"""
    
    execution_steps = len([s for s in self.reasoning_history if s.step_type == "execution"])
    validation_steps = len([s for s in self.reasoning_history if s.step_type == "validation"])
    reflection_steps = len([s for s in self.reasoning_history if s.step_type == "reflection"])
    
    # Fatores positivos
    base_confidence = min(1.0, (execution_steps * 0.3 + validation_steps * 0.2))
    
    # Penalidades
    loop_penalty = 0.3 if self._detect_reasoning_loop() else 0.0
    reflection_penalty = reflection_steps * 0.1
    
    return max(0.0, base_confidence - loop_penalty - reflection_penalty)
```

### 5. ğŸ”„ Reflection & Adjustment
**Objetivo**: Aprender com erros e ajustar estratÃ©gia dinamicamente

```python
def reflect_and_adjust(self, what_went_wrong: str) -> TaskPlan:
    """ReflexÃ£o crÃ­tica e ajuste de estratÃ©gia"""
    
    self.add_reasoning_step(
        "reflection",
        f"Reflecting on issues: {what_went_wrong}",
        "Analyzing failures and adjusting approach",
        "Recreate improved plan"
    )
    
    # Atualiza assumptions baseado no que aprendeu
    if "timeout" in what_went_wrong.lower():
        self._adjust_timeout_assumptions()
    elif "no results" in what_went_wrong.lower():
        self._adjust_search_strategy()
    
    # Gera novo plano melhorado
    improved_plan = self._create_improved_plan(what_went_wrong)
    
    return improved_plan
```

## ğŸ”— IntegraÃ§Ã£o com Sistema Multi-Agente

### ReAct no Lead Researcher
```python
class OpenAILeadResearcher:
    def __init__(self):
        self.reasoner = ReActReasoner(f"OpenAI Lead Researcher ({self.agent_id})")
    
    async def plan(self, context: AgentContext):
        """Planning com ReAct reasoning"""
        
        # 1. Fact gathering
        facts = self.reasoner.gather_facts(
            task=f"Research planning for: {context.query}",
            context=f"Objective: {context.objective}"
        )
        
        # 2. Enhanced reasoning com anÃ¡lise crÃ­tica
        facts.assumptions = self._create_sophisticated_assumptions(context.query)
        
        # 3. Planning
        plan = self.reasoner.create_plan(
            objective=f"Create comprehensive research plan for: {context.query}",
            available_resources=["OpenAI gpt-4.1-mini", "RAG subagents"]
        )
        
        # 4. Execute planning (LLM ou heuristic)
        return await self._execute_planning_with_reasoning(context, facts, plan)
```

### Continuidade na SÃ­ntese
```python
def _advanced_ai_synthesis(self, tasks, successful_results):
    """SÃ­ntese que continua o reasoning inicial"""
    
    # Integra trace completo do reasoning
    reasoning_trace = self.reasoner.get_reasoning_trace()
    
    synthesis_prompt = f"""
    CONTEXTO DO PROCESSO DE REASONING:
    {reasoning_trace}
    
    INSTRUÃ‡Ã•ES PARA SÃNTESE CRÃTICA AVANÃ‡ADA:
    1. **Continuidade do Reasoning**: Continue o processo iniciado no planejamento
    2. **ValidaÃ§Ã£o CrÃ­tica**: Avalie consistÃªncia baseado no reasoning trace  
    3. **ReflexÃ£o sobre o Processo**: Avalie se resultados confirmam assumptions iniciais
    4. **Gaps e LimitaÃ§Ãµes**: Identifique lacunas baseado no planejado vs encontrado
    
    Produza sÃ­ntese que demonstre continuidade e evoluÃ§Ã£o do reasoning inicial.
    """
    
    # Final validation
    validation = self.reasoner.validate_progress(f"Synthesis for: {tasks[0]['query']}")
    
    return synthesized_result
```

## ğŸ“Š Trace Visualization

### Reasoning Trace Format
```python
def get_reasoning_trace(self) -> str:
    """Gera trace legÃ­vel do processo completo"""
    
    trace = f"=== Trace de RaciocÃ­nio - {self.agent_name} ===\n\n"
    
    for i, step in enumerate(self.reasoning_history, 1):
        trace += f"ğŸ” Passo {i}: {step.step_type.upper()}\n"
        trace += f"â° {step.timestamp.strftime('%H:%M:%S')}\n"
        trace += f"ğŸ’­ {step.content}\n"
        
        if step.observations:
            trace += f"ğŸ‘ï¸ ObservaÃ§Ãµes: {step.observations}\n"
        
        if step.next_action:
            trace += f"â¡ï¸ PrÃ³xima aÃ§Ã£o: {step.next_action}\n"
        
        trace += "\n" + "â”€" * 50 + "\n\n"
    
    return trace
```

**Exemplo de Trace**:
```
=== Trace de RaciocÃ­nio - OpenAI Lead Researcher (abc-123) ===

ğŸ” Passo 1: FACT_GATHERING
â° 14:32:15
ğŸ’­ Coletando fatos para: Research planning for Zep temporal knowledge graphs
ğŸ‘ï¸ ObservaÃ§Ãµes: Query complexity: high, Technical depth: high
â¡ï¸ PrÃ³xima aÃ§Ã£o: Analisar fatos dados e relembrar conhecimento relevante

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ” Passo 2: PLANNING  
â° 14:32:16
ğŸ’­ Criando plano para: Create comprehensive research plan for Zep temporal KG
ğŸ‘ï¸ ObservaÃ§Ãµes: Recursos disponÃ­veis: ['OpenAI gpt-4.1-mini', 'RAG subagents']
â¡ï¸ PrÃ³xima aÃ§Ã£o: Desenvolver plano estruturado em etapas

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ” Passo 3: EXECUTION
â° 14:32:17  
ğŸ’­ Executando: LLM-based decomposition informed by ReAct reasoning
ğŸ‘ï¸ ObservaÃ§Ãµes: Integrating manual reasoning with gpt-4.1-mini for optimal focus area selection
â¡ï¸ PrÃ³xima aÃ§Ã£o: Avaliar resultado e determinar prÃ³ximo passo
```

## ğŸ¯ Benefits do ReAct Pattern

### 1. **Structured Thinking**
- **Antes**: Pensamento livre e nÃ£o estruturado
- **Depois**: Categorias claras (fact gathering, planning, execution, validation, reflection)

### 2. **Continuous Validation**
- **Antes**: ValidaÃ§Ã£o manual ao final
- **Depois**: ValidaÃ§Ã£o automÃ¡tica a cada step com mÃ©tricas de confianÃ§a

### 3. **Loop Detection**
- **Antes**: Loops passavam despercebidos
- **Depois**: DetecÃ§Ã£o automÃ¡tica e ajuste de estratÃ©gia

### 4. **Traceability**
- **Antes**: DifÃ­cil rastrear como decisÃµes foram tomadas
- **Depois**: Trace completo de todo o processo de reasoning

### 5. **Dynamic Adjustment**
- **Antes**: EstratÃ©gia fixa durante execuÃ§Ã£o
- **Depois**: Ajustes dinÃ¢micos baseados em feedback

## ğŸ”§ Configuration & Tuning

### Reasoning Parameters
```python
class ReActConfig:
    max_iterations: int = 10
    confidence_threshold: float = 0.7
    loop_detection_window: int = 4
    reflection_trigger_threshold: int = 3
    
    # Timeouts
    step_timeout: float = 30.0
    total_reasoning_timeout: float = 300.0
    
    # Quality metrics
    min_execution_steps: int = 1
    min_confidence_for_completion: float = 0.5
```

### Customization Points
```python
class CustomReActReasoner(ReActReasoner):
    def _assess_task_completion(self, original_task: str) -> bool:
        """Custom completion assessment"""
        # Domain-specific completion logic
        return super()._assess_task_completion(original_task)
    
    def _determine_next_action(self) -> Optional[str]:
        """Custom action determination"""
        # Domain-specific next action logic
        return super()._determine_next_action()
```

---

## ğŸ“š Links Relacionados

- [ğŸ¤– Sistema Multi-Agente](multi-agent.md) - Como ReAct se integra com agentes
- [ğŸ›ï¸ Arquitetura](architecture.md) - VisÃ£o geral do sistema
- [ğŸ“Š Pipeline RAG](rag-pipeline.md) - RAG com reasoning  
- [âš¡ Performance](performance.md) - Impacto do reasoning na performance
- [ğŸ”§ Troubleshooting](troubleshooting.md) - Debug de reasoning issues